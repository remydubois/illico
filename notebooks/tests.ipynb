{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b93300c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6931472, 0.6931472], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csc_h1.data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc76f2af",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypingError",
     "evalue": "Failed in nopython mode pipeline (step: nopython frontend)\ntuple index out of range\nDuring: typing of static-get-item at /var/folders/y7/p3ldjm_s1xn8knz8bqf8f9p00000gn/T/ipykernel_3600/3742943492.py (14)\n\nFile \"../../../../../../../var/folders/y7/p3ldjm_s1xn8knz8bqf8f9p00000gn/T/ipykernel_3600/3742943492.py\", line 14:\n<source missing, REPL/exec in use?>\n\nDuring: Pass nopython_type_inference",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypingError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     19\u001b[39m h1.X = h1.layers[\u001b[33m\"\u001b[39m\u001b[33mcsc\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     20\u001b[39m csc_h1 = scipy_to_nb(h1.X)\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[43m_sort_csc_columns_inplace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsc_h1\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m;\n\u001b[32m     22\u001b[39m get_ipython().run_line_magic(\u001b[33m'\u001b[39m\u001b[33mtimeit\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m-n 1 -r 1 _sort_csc_columns_inplace(csc_h1)\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     23\u001b[39m h1 = ad.read_h5ad(\u001b[33m'\u001b[39m\u001b[33m../vcc_h1_904_genes.h5ad\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/perso/repos/illico/.venv/lib/python3.13/site-packages/numba/core/dispatcher.py:424\u001b[39m, in \u001b[36m_DispatcherBase._compile_for_args\u001b[39m\u001b[34m(self, *args, **kws)\u001b[39m\n\u001b[32m    420\u001b[39m         msg = (\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e).rstrip()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mThis error may have been caused \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    421\u001b[39m                \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mby the following argument(s):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00margs_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    422\u001b[39m         e.patch_message(msg)\n\u001b[32m--> \u001b[39m\u001b[32m424\u001b[39m     \u001b[43merror_rewrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtyping\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m errors.UnsupportedError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    426\u001b[39m     \u001b[38;5;66;03m# Something unsupported is present in the user code, add help info\u001b[39;00m\n\u001b[32m    427\u001b[39m     error_rewrite(e, \u001b[33m'\u001b[39m\u001b[33munsupported_error\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/perso/repos/illico/.venv/lib/python3.13/site-packages/numba/core/dispatcher.py:365\u001b[39m, in \u001b[36m_DispatcherBase._compile_for_args.<locals>.error_rewrite\u001b[39m\u001b[34m(e, issue_type)\u001b[39m\n\u001b[32m    363\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    364\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m365\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[31mTypingError\u001b[39m: Failed in nopython mode pipeline (step: nopython frontend)\ntuple index out of range\nDuring: typing of static-get-item at /var/folders/y7/p3ldjm_s1xn8knz8bqf8f9p00000gn/T/ipykernel_3600/3742943492.py (14)\n\nFile \"../../../../../../../var/folders/y7/p3ldjm_s1xn8knz8bqf8f9p00000gn/T/ipykernel_3600/3742943492.py\", line 14:\n<source missing, REPL/exec in use?>\n\nDuring: Pass nopython_type_inference"
     ]
    }
   ],
   "source": [
    "from illico.utils.ranking import _sort_csc_columns_inplace\n",
    "from illico.utils.type import scipy_to_nb\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "\n",
    "@njit(nogil=True, cache=False)\n",
    "def _sort_csc_columns_inplace(csc_matrix) -> None:\n",
    "    \"\"\"Sort CSC columns in place.\n",
    "\n",
    "    Args:\n",
    "        csc_matrix (CSCMatrix): Input CSC matrix.\n",
    "    \"\"\"\n",
    "    # _assert_is_csc(csc_matrix)\n",
    "    for j in range(csc_matrix.shape[1]):\n",
    "        csc_matrix.data[csc_matrix.indptr[j] : csc_matrix.indptr[j + 1]].sort()\n",
    "\n",
    "\n",
    "h1 = ad.read_h5ad('../vcc_h1_904_genes.h5ad')\n",
    "h1.X = h1.layers[\"csc\"]\n",
    "csc_h1 = scipy_to_nb(h1.X)\n",
    "_sort_csc_columns_inplace(csc_h1);\n",
    "%timeit -n 1 -r 1 _sort_csc_columns_inplace(csc_h1)\n",
    "h1 = ad.read_h5ad('../vcc_h1_904_genes.h5ad')\n",
    "h1.X = h1.layers[\"csc\"]\n",
    "csc_h1 = scipy_to_nb(h1.X)\n",
    "%timeit -n 1 -r 1 _sort_csc_columns_inplace.__wrapped__(csc_h1)\n",
    "\n",
    "# h1 = ad.read_h5ad('../vcc_h1_904_genes.h5ad')\n",
    "# h1.X = h1.layers[\"csc\"]\n",
    "# sc.pp.normalize_total(h1, target_sum=1e4)\n",
    "# csc_h1 = scipy_to_nb(h1.X.tocsc())\n",
    "# # _sort_csc_columns_inplace(csc_h1);\n",
    "# %timeit -n 1 -r 1 _sort_csc_columns_inplace(csc_h1)\n",
    "# h1 = ad.read_h5ad('../vcc_h1_904_genes.h5ad')\n",
    "# h1.X = h1.layers[\"csc\"]\n",
    "# sc.pp.normalize_total(h1, target_sum=1e4)\n",
    "# csc_h1 = scipy_to_nb(h1.X.tocsc())\n",
    "# %timeit -n 1 -r 1 _sort_csc_columns_inplace.__wrapped__(csc_h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bd763209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.66 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n",
      "1.97 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n",
      "281 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "import anndata as ad\n",
    "import numpy as np\n",
    "from illico.utils.type import scipy_to_nb\n",
    "from numba import njit\n",
    "import scanpy as sc\n",
    "\n",
    "h1 = ad.read_h5ad('../vcc_h1_904_genes.h5ad')\n",
    "h1.X = h1.layers[\"csc\"]\n",
    "# sc.pp.normalize_total(h1, target_sum=1e4)\n",
    "# csc_h1 = scipy_to_nb(h1.X)\n",
    "csc_h1 = h1.X\n",
    "nb_argsort = njit(nogil=True)(lambda x: np.argsort(x))\n",
    "nb_argsort(csc_h1.data[csc_h1.indptr[0]:csc_h1.indptr[1]])\n",
    "%timeit -n 1 -r 1 [nb_argsort(csc_h1.data[csc_h1.indptr[i]:csc_h1.indptr[i+1]]) for i in range(csc_h1.shape[1])]\n",
    "%timeit -n 1 -r 1 [np.argsort(csc_h1.data[csc_h1.indptr[i]:csc_h1.indptr[i+1]]) for i in range(csc_h1.shape[1])]\n",
    "%timeit -n 1 -r 1 [csc_h1.data[csc_h1.indptr[i]:csc_h1.indptr[i+1]].sort() for i in range(csc_h1.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bb46c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-09 s\n",
      "\n",
      "Total time: 5.80105 s\n",
      "File: /Users/remydubois/Documents/perso/repos/illico/illico/ovr/dense_ovr.py\n",
      "Function: dense_ovr_mwu_kernel at line 14\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    14                                           def dense_ovr_mwu_kernel(\n",
      "    15                                               X: np.ndarray,\n",
      "    16                                               grpc: GroupContainer,\n",
      "    17                                               use_continuity: bool = True,\n",
      "    18                                               is_log1p: bool = False,\n",
      "    19                                           ) -> tuple[np.ndarray]:\n",
      "    20                                               \"\"\" Compute OVR ranksum test on a dense matrix of expression counts.\n",
      "    21                                           \n",
      "    22                                               Args:\n",
      "    23                                                   X (np.ndarray): Input dense raw counts matrix\n",
      "    24                                                   grpc (GroupContainer): GroupContainer\n",
      "    25                                                   use_continuity (bool, optional): Apply continuity factor or not. Defaults to True.\n",
      "    26                                                   is_log1p (bool, optional): User-indicated flag telling if data underwent log1p \n",
      "    27                                                   transformation or not. Defaults to False.\n",
      "    28                                           \n",
      "    29                                               Returns:\n",
      "    30                                                   tuple[np.ndarray]: Two-sided p-values, U-statistic and fold change.\n",
      "    31                                                   Each np.ndarray of shape (n_groups, n_genes)\n",
      "    32                                               \"\"\"\n",
      "    33                                               # TODO: handle tie correction properly\n",
      "    34         1       1000.0   1000.0      0.0      contin_corr = 0.5 if use_continuity else 0.0\n",
      "    35                                           \n",
      "    36                                               # Get ranks and tie sums\n",
      "    37         1       5000.0   5000.0      0.0      tie_sum = np.empty(X.shape[1], dtype=np.float64)\n",
      "    38         1      61000.0  61000.0      0.0      ranksums = np.zeros(shape=(grpc.counts.size, X.shape[1]), dtype=np.float64)\n",
      "    39       905     606000.0    669.6      0.0      for j in range(X.shape[1]):\n",
      "    40       904 3591831000.0 3.97e+06     61.9          idxs = np.argsort(X[:, j])\n",
      "    41      1808  967353000.0 535040.4     16.7          col_tie_sum = _accumulate_group_ranksums_from_argsort(\n",
      "    42       904    1980000.0   2190.3      0.0              X[:, j], idxs, grpc.encoded_groups, ranksums[:, j]\n",
      "    43                                                   )\n",
      "    44       904    1537000.0   1700.2      0.0          tie_sum[j] = col_tie_sum\n",
      "    45                                           \n",
      "    46                                               # Compute U stats\n",
      "    47         1       2000.0   2000.0      0.0      n = X.shape[0]\n",
      "    48         1      54000.0  54000.0      0.0      n_ref = np.expand_dims(n - grpc.counts, -1)  # (g, 1)\n",
      "    49         1       7000.0   7000.0      0.0      n_tgt = np.expand_dims(grpc.counts, -1)  # (g, 1)\n",
      "    50         1     159000.0 159000.0      0.0      U = (n_ref * n_tgt + n_tgt * (n_tgt + 1) / 2) - ranksums\n",
      "    51         1       5000.0   5000.0      0.0      mu = n_ref * n_tgt / 2.0\n",
      "    52                                               # Compute pvals\n",
      "    53                                               # TODO: if the not jitted, maybe this double loop can be shelled inside a njit function\n",
      "    54         1       4000.0   4000.0      0.0      pvals = np.empty(shape=(grpc.counts.size, X.shape[1]), dtype=np.float64)\n",
      "    55       905     214000.0    236.5      0.0      for j in range(X.shape[1]):\n",
      "    56    137408   37108000.0    270.1      0.6          for k in range(grpc.counts.size):\n",
      "    57    273008  161726000.0    592.4      2.8              pvals[k, j] = compute_pval(\n",
      "    58    136504   35897000.0    263.0      0.6                  n_ref=n_ref[k, 0],\n",
      "    59    136504   33114000.0    242.6      0.6                  n_tgt=n_tgt[k, 0],\n",
      "    60    136504   27119000.0    198.7      0.5                  n=n,\n",
      "    61    136504   32192000.0    235.8      0.6                  tie_sum=tie_sum[j],\n",
      "    62    136504   35704000.0    261.6      0.6                  U=U[k, j],\n",
      "    63    136504   32937000.0    241.3      0.6                  mu=mu[k, 0],\n",
      "    64    136504   27210000.0    199.3      0.5                  contin_corr=contin_corr,\n",
      "    65                                                       )\n",
      "    66                                           \n",
      "    67                                               # Get fold change\n",
      "    68         1  814222000.0 8.14e+08     14.0      fold_change = dense_fold_change(X, grpc=grpc, is_log1p=is_log1p)\n",
      "    69                                           \n",
      "    70                                               # TODO: unify U names across funcs\n",
      "    71         1       1000.0   1000.0      0.0      return pvals, U, fold_change"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext line_profiler\n",
    "from illico.asymptotic_wilcoxon import encode_and_count_groups\n",
    "from illico.ovr.sparse_ovr import csc_ovr_mwu_kernel_over_contiguous_col_chunk\n",
    "from illico.ovr import dense_ovr_mwu_kernel\n",
    "from illico.utils.type import scipy_to_nb\n",
    "import anndata as ad\n",
    "\n",
    "\n",
    "h1 = ad.read_h5ad('../vcc_h1_904_genes.h5ad')\n",
    "# X = scipy_to_nb(h1.layers[\"csc\"])\n",
    "# grpc = encode_and_count_groups(h1.obs['target_gene'].tolist(), ref_group=None)\n",
    "# csc_ovr_mwu_kernel_over_contiguous_col_chunk(X, 0, 904, grpc, is_log1p=False);\n",
    "# %lprun -f csc_ovr_mwu_kernel_over_contiguous_col_chunk csc_ovr_mwu_kernel_over_contiguous_col_chunk(X, 0, 904, grpc, is_log1p=False)\n",
    "X = scipy_to_nb(h1.layers[\"dense\"])\n",
    "grpc = encode_and_count_groups(h1.obs['target_gene'].tolist(), ref_group=None)\n",
    "dense_ovr_mwu_kernel(X, grpc, is_log1p=False);\n",
    "%lprun -f dense_ovr_mwu_kernel dense_ovr_mwu_kernel(X, grpc, is_log1p=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eede92d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "h1_small = h1[:, :9].copy()\n",
    "h1_small.layers[\"csr\"] = h1_small.layers[\"csr\"].copy()\n",
    "h1_small.layers[\"dense\"] = h1_small.layers[\"dense\"].copy()\n",
    "h1_small.layers[\"csc\"] = h1_small.layers[\"csc\"].copy()\n",
    "del h1_small.X\n",
    "h1_small.write('../vcc_h1_9_genes.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a64676de",
   "metadata": {},
   "outputs": [],
   "source": [
    "h1_small = ad.read_h5ad('../vcc_h1_904_genes.h5ad')\n",
    "from illico.asymptotic_wilcoxon import asymptotic_wilcoxon\n",
    "h1_small.X = h1_small.layers[\"csc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41824e74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d272419595848e4a3b9a986f199ff3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.3 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b598c6868974d898ee3829f93bb4f13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.3 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "import anndata as ad\n",
    "from illico.asymptotic_wilcoxon import asymptotic_wilcoxon\n",
    "\n",
    "# h1 = ad.read_h5ad('/Users/remydubois/Documents/repos/vcc/data/competition_support_set/competition_train.h5')[:, :1808*2].copy()\n",
    "h1 = ad.read_h5ad('/Users/remydubois/Documents/repos/vcc/data/competition_support_set/competition_train.h5')\n",
    "# print(h1.shape)\n",
    "# asymptotic_wilcoxon(h1[:, :1], is_log1p=False, group_keys=\"target_gene\", reference_group=\"non-targeting\", n_threads=1, batch_size=64)\n",
    "# %timeit -n 1 -r 1 asymptotic_wilcoxon(h1, is_log1p=False, group_keys=\"target_gene\", reference_group=\"non-targeting\", n_threads=1, batch_size=64)\n",
    "# %timeit -n 1 -r 1 asymptotic_wilcoxon(h1, is_log1p=False, group_keys=\"target_gene\", reference_group=\"non-targeting\", n_threads=2, batch_size=64)\n",
    "# %timeit -n 1 -r 1 asymptotic_wilcoxon(h1, is_log1p=False, group_keys=\"target_gene\", reference_group=\"non-targeting\", n_threads=4, batch_size=64)\n",
    "# %timeit -n 1 -r 1 asymptotic_wilcoxon(h1, is_log1p=False, group_keys=\"target_gene\", reference_group=\"non-targeting\", n_threads=8, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b80ea247",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/remydubois/Documents/perso/repos/illico/illico/utils/math.py:83: UserWarning: The data appears to be log1p transformed (non-integer values found). However, 'is_log1p' is set to False. Please ensure that this is intended, as it may affect the results.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from illico.utils.math import _warn_log1p\n",
    "\n",
    "_warn_log1p(h1.X, is_log1p=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b4ecead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eaa4c30f86341aaaa2f709a955306ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-09 s\n",
      "\n",
      "Total time: 10.2848 s\n",
      "File: /Users/remydubois/Documents/perso/repos/illico/illico/asymptotic_wilcoxon.py\n",
      "Function: asymptotic_wilcoxon at line 19\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    19                                           def asymptotic_wilcoxon(\n",
      "    20                                               adata: ad.AnnData,\n",
      "    21                                               is_log1p: bool,\n",
      "    22                                               group_keys: str,\n",
      "    23                                               reference_group: str | None = None,\n",
      "    24                                               n_threads: int = 1,\n",
      "    25                                               batch_size: int = 256,\n",
      "    26                                           ):\n",
      "    27                                               \"\"\"\"\"\"\n",
      "    28                                           \n",
      "    29         1      11000.0  11000.0      0.0      X = adata.X\n",
      "    30                                               # Do not transform anything, just warn if needed\n",
      "    31                                               # _warn_log1p(X, is_log1p=is_log1p)\n",
      "    32                                           \n",
      "    33                                               # Process the groups information\n",
      "    34         1    3416000.0 3.42e+06      0.0      raw_groups = adata.obs[group_keys].tolist()\n",
      "    35         2   97469000.0 4.87e+07      0.9      group_container = encode_and_count_groups(\n",
      "    36         1       1000.0   1000.0      0.0          groups=raw_groups, ref_group=reference_group\n",
      "    37                                               )\n",
      "    38                                               # logger.info(\"Processed grouping information\")\n",
      "    39                                           \n",
      "    40         1       2000.0   2000.0      0.0      _, n_genes = X.shape\n",
      "    41                                               \n",
      "    42                                               # Test all the possible use cases\n",
      "    43                                               # TODO: make the generator unordered\n",
      "    44         1          0.0      0.0      0.0      results = []\n",
      "    45                                               # Adapt batch size to leverage multithreading regarding the number of genes, if requested\n",
      "    46         1       2000.0   2000.0      0.0      batch_size = min(batch_size, math.ceil(n_genes / n_threads))\n",
      "    47         1      13000.0  13000.0      0.0      bounds = np.append(np.arange(0, n_genes, batch_size), n_genes)\n",
      "    48         1       5000.0   5000.0      0.0      iterator = list(zip(bounds[:-1], bounds[1:]))\n",
      "    49                                               # logger.info(f\"Batching data by {batch_size} columns ({len(iterator)} batches to process)\")\n",
      "    50         2     695000.0 347500.0      0.0      with Parallel(n_threads, prefer=\"threads\", return_as=\"generator\") as pool:\n",
      "    51         2   10894000.0 5.45e+06      0.1          with tqdm(total=len(iterator)) as pbar:\n",
      "    52         1       1000.0   1000.0      0.0              if reference_group is None:  # ovr use case\n",
      "    53                                                           pbar.set_description(\"Running one-versus-all MannWhitney-U tests\")\n",
      "    54                                                           op = delayed(ovr_mwu_over_col_contiguous_chunk)\n",
      "    55                                                       else:  # ovo use case\n",
      "    56         1     232000.0 232000.0      0.0                  pbar.set_description(\"Running one-versus-ref MannWhitney-U tests\")\n",
      "    57         1      12000.0  12000.0      0.0                  op = delayed(ovo_mwu_over_contiguous_col_chunk)\n",
      "    58        10 9777223000.0 9.78e+08     95.1              for i, (pv, ustat, fc) in enumerate(\n",
      "    59         1    1460000.0 1.46e+06      0.0                  pool(op(X, lb, ub, group_container, is_log1p) for lb, ub in iterator)\n",
      "    60                                                       ):\n",
      "    61         8   79342000.0 9.92e+06      0.8                  pbar.update()  # refresh after processing is done\n",
      "    62        16   25179000.0 1.57e+06      0.2                  features = np.tile(\n",
      "    63         8     414000.0  51750.0      0.0                      adata.var_names[bounds[i] : bounds[i + 1]], pv.shape[0]\n",
      "    64                                                           )\n",
      "    65        16   56952000.0 3.56e+06      0.6                  perts = np.repeat(\n",
      "    66         8      16000.0   2000.0      0.0                      group_container.unique_raw_groups, bounds[i + 1] - bounds[i]\n",
      "    67                                                           )\n",
      "    68        16      12000.0    750.0      0.0                  results.append(\n",
      "    69        16  219025000.0 1.37e+07      2.1                      pd.DataFrame(\n",
      "    70         8       7000.0    875.0      0.0                          {\n",
      "    71         8      11000.0   1375.0      0.0                              \"p_value\": pv.ravel(),\n",
      "    72         8       3000.0    375.0      0.0                              \"statistic\": ustat.ravel(),\n",
      "    73         8       1000.0    125.0      0.0                              \"fold_change\": fc.ravel(),\n",
      "    74         8       2000.0    250.0      0.0                              \"feature\": features,\n",
      "    75         8       1000.0    125.0      0.0                              \"pert\": perts,\n",
      "    76                                                                   }\n",
      "    77                                                               )\n",
      "    78                                                           )\n",
      "    79                                                           # results.append(r)\n",
      "    80                                                       # results = TestResults(\n",
      "    81                                                       #     pvalue=np.concatenate([r.pvalue for r in results]),\n",
      "    82                                                       #     statistic=np.concatenate([r.statistic for r in results]),\n",
      "    83                                                       #     axis=1,\n",
      "    84                                                       # )\n",
      "    85         1    4272000.0 4.27e+06      0.0          results = pd.concat(results, axis=0)\n",
      "    86         1          0.0      0.0      0.0          if reference_group is not None:\n",
      "    87         1    8101000.0  8.1e+06      0.1              results = results.query(f'pert != \"{reference_group}\"')\n",
      "    88                                                   # results.columns = adata.var_names.copy()\n",
      "    89                                                   # results[\"pert\"] = group_container.unique_raw_groups.repeat(len(iterator))\n",
      "    90         1       1000.0   1000.0      0.0          \"\"\"\n",
      "    91                                                       This case is harder than the OVR use case, because:\n",
      "    92                                                       1. If input is dense, then it's easy we can slice easily over rows (or group of rows) or columns and parallelize the way we want\n",
      "    93                                                       2. If input is CSR, we can easily slice the perturbations, and easily slice contiguous columns\n",
      "    94                                                       3. If input is CSC, we can easily slice along the columns, BUT NOT ALONG THE PERTURBATIONS because perturbations are non-contiguous along axis 0\n",
      "    95                                           \n",
      "    96                                                       So the answer is simple: if we want a unified parallelism scheme, it has to be along the columns. Now:\n",
      "    97                                                       - For the dense use case, there is no problem.\n",
      "    98                                                       - For the sparse use case, the OVO kernel requires data to be CSC, so:\n",
      "    99                                                           a) If input is CSC, it means we do overall: big CSC ->  vertical chunk of CSC -> horizontal chunk of vertical chunk of CSC -> test\n",
      "   100                                                           b) If input is CSR, it means we do: big CSR  ->  vertical chunk of CSR -> horizontal chunk of vertical chunk of CSR -> CSC -> test\n",
      "   101                                                       For a), the second chunking is suboptimal because we chunk along 0 a CSC matrix, but because it has little columns this is fast.\n",
      "   102                                                       For b), this is a lot of conversion but I believe they all happen on small matrices so this should be fine.\n",
      "   103                                           \n",
      "   104                                                       Conclusion: runtime on H1 is ~25 seconds for CSC, 25 seconds for CSR so still very nice.\n",
      "   105                                                       TO KEEP IN MIND: there is **no** way to optimize any other parallelism than column-based actually, the current idea (parallelizing over the\n",
      "   106                                                       perturbations) will be very slow, or require a brand new CSR allocation (which we don't want), to function.\n",
      "   107                                                       \"\"\"\n",
      "   108         1          0.0      0.0      0.0      return results"
     ]
    }
   ],
   "source": [
    "%load_ext line_profiler\n",
    "\n",
    "%lprun -f asymptotic_wilcoxon asymptotic_wilcoxon(h1, is_log1p=False, group_keys=\"target_gene\", reference_group=\"non-targeting\", n_threads=2, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e501565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.9 ms ± 1.19 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "from typing import Any\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "GroupContainer = namedtuple(\n",
    "    \"GroupContainer\",\n",
    "    [\n",
    "        \"raw_groups\",\n",
    "        \"ref_group\",\n",
    "        \"encoded_groups\",\n",
    "        \"unique_raw_groups\",\n",
    "        \"counts\",\n",
    "        \"indices\",\n",
    "        \"indptr\",\n",
    "        \"encoded_ref_group\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "def encode_and_count_groups(groups: np.ndarray, ref_group: Any) -> GroupContainer:\n",
    "    \"\"\"Groups are encoded no matter what they contain, string, floats, integers, etc\"\"\"\n",
    "    # sorted_groups = groups[group_indices]\n",
    "    # diff = np.diff(sorted_groups)\n",
    "    unique_groups, group_counts = np.unique(groups, return_counts=True)\n",
    "    groups_mapping = {g: i for i, g in enumerate(unique_groups)}\n",
    "    encoded_groups = np.array([groups_mapping[g] for g in groups])\n",
    "    # This should sort them in the same order as the first np.unique\n",
    "    group_indices = np.argsort(groups)\n",
    "    group_indptr = np.cumsum(np.insert(group_counts, 0, 0))\n",
    "\n",
    "    return GroupContainer(\n",
    "        raw_groups=groups,\n",
    "        ref_group=ref_group,\n",
    "        encoded_groups=encoded_groups,\n",
    "        unique_raw_groups=unique_groups,\n",
    "        counts=group_counts,\n",
    "        indices=group_indices,\n",
    "        indptr=group_indptr,\n",
    "        encoded_ref_group=-1 if ref_group is None else groups_mapping[ref_group], # Weirdly enough, this must be -1 and not None, otherwise Numba fails to compile various functions, especially branching\n",
    "    )\n",
    "\n",
    "groups = h1.obs.target_gene.values\n",
    "%timeit encode_and_count_groups(groups, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "424a31e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48.9 ms ± 903 μs per loop (mean ± std. dev. of 5 runs, 5 loops each)\n",
      "49.1 ms ± 461 μs per loop (mean ± std. dev. of 5 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def unique_with_counts(x):\n",
    "    idxs = np.argsort(x.ravel())\n",
    "    aux = x[idxs]\n",
    "    mask = np.empty(aux.shape, dtype=bool)\n",
    "    mask[0] = True\n",
    "    mask[1:] = aux[1:] != aux[:-1]\n",
    "    uniques = aux[mask]\n",
    "    counts = np.diff(np.nonzero(mask)[0].tolist() + [len(aux)])\n",
    "    return uniques, counts\n",
    "\n",
    "groups = np.array(h1.obs.target_gene.values)\n",
    "%timeit -n 5 -r 5 unique_with_counts(groups)\n",
    "%timeit -n 5 -r 5 np.unique(groups, return_counts=True)\n",
    "uniques, counts = unique_with_counts(groups)\n",
    "_u, _c = np.unique(groups, return_counts=True)\n",
    "np.testing.assert_allclose(counts, _c)\n",
    "assert np.equal(uniques, _u).all() == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b86a202d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.2 ms ± 963 μs per loop (mean ± std. dev. of 5 runs, 5 loops each)\n",
      "5.25 ms ± 206 μs per loop (mean ± std. dev. of 5 runs, 5 loops each)\n",
      "17.8 ms ± 1.64 ms per loop (mean ± std. dev. of 5 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def f(groups, ref_group):\n",
    "    encoded_groups = LabelEncoder().fit_transform(groups.ravel())\n",
    "    idxs = np.argsort(encoded_groups.ravel())\n",
    "    aux = encoded_groups[idxs]\n",
    "    mask = np.empty(aux.shape, dtype=bool)\n",
    "    mask[0] = True\n",
    "    mask[1:] = aux[1:] != aux[:-1]\n",
    "    uniques = aux[mask]\n",
    "    counts = np.diff(np.nonzero(mask)[0].tolist() + [len(aux)])\n",
    "    group_indptr = np.cumsum(np.insert(counts, 0, 0))\n",
    "    return GroupContainer(\n",
    "        raw_groups=groups,\n",
    "        ref_group=ref_group,\n",
    "        encoded_groups=encoded_groups,\n",
    "        unique_raw_groups=groups[mask],\n",
    "        counts=counts,\n",
    "        indices=idxs,\n",
    "        indptr=group_indptr,\n",
    "        encoded_ref_group=-1\n",
    "    )\n",
    "\n",
    "le = LabelEncoder()\n",
    "%timeit -n 5 -r 5 le.fit_transform(groups)\n",
    "%timeit -n 5 -r 5 unique_with_counts(encoded_groups)\n",
    "encoded_groups = le.fit_transform(groups)\n",
    "unique, counts = unique_with_counts(encoded_groups)\n",
    "%timeit -n 5 -r 5 f(groups, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9eecb5",
   "metadata": {},
   "source": [
    "# Memory profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ef235e",
   "metadata": {},
   "source": [
    "from "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74740233",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata as ad\n",
    "import numpy as np\n",
    "from illico.asymptotic_wilcoxon import asymptotic_wilcoxon\n",
    "from pdex import parallel_differential_expression\n",
    "import scanpy as sc\n",
    "\n",
    "adata = ad.read_h5ad('/Users/remydubois/Documents/repos/vcc/data/competition_support_set/competition_train.h5')\n",
    "# adata.X = adata.layers[\"csc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61707158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pdex._single_cell:Auto-Detected log1p for dataset.\n",
      "INFO:pdex._single_cell:Log1p status: True\n",
      "INFO:pdex._single_cell:Precomputing masks for each target gene\n",
      "Identifying target masks: 100%|██████████| 151/151 [00:00<00:00, 19080.53it/s]\n",
      "INFO:pdex._single_cell:Precomputing variable indices for each feature\n",
      "Identifying variable indices: 100%|██████████| 90/90 [00:00<00:00, 1955893.06it/s]\n",
      "INFO:pdex._single_cell:Creating shared memory memory matrix for parallel computing\n",
      "INFO:pdex._single_cell:Creating generator of all combinations: N=13590\n",
      "INFO:pdex._single_cell:Creating generator of all batches: N=136\n",
      "INFO:pdex._single_cell:Initializing parallel processing pool\n",
      "INFO:pdex._single_cell:Processing batches\n",
      "Processing batches: 100%|██████████| 136/136 [00:29<00:00,  4.68it/s]\n",
      "INFO:pdex._single_cell:Flattening results\n",
      "INFO:pdex._single_cell:Closing shared memory pool\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 1810.25 MiB, increment: 659.38 MiB\n"
     ]
    }
   ],
   "source": [
    "%load_ext memory_profiler\n",
    "\n",
    "%memit -c parallel_differential_expression(adata, groupby_key=\"target_gene\", reference=\"non-targeting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2317fbcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pdex._single_cell:Auto-Detected log1p for dataset.\n",
      "INFO:pdex._single_cell:Log1p status: True\n",
      "INFO:pdex._single_cell:Precomputing masks for each target gene\n",
      "Identifying target masks: 100%|██████████| 151/151 [00:00<00:00, 19063.30it/s]\n",
      "INFO:pdex._single_cell:Precomputing variable indices for each feature\n",
      "Identifying variable indices: 100%|██████████| 90/90 [00:00<00:00, 1966080.00it/s]\n",
      "INFO:pdex._single_cell:Creating shared memory memory matrix for parallel computing\n",
      "INFO:pdex._single_cell:Creating generator of all combinations: N=13590\n",
      "INFO:pdex._single_cell:Creating generator of all batches: N=136\n",
      "INFO:pdex._single_cell:Initializing parallel processing pool\n",
      "INFO:pdex._single_cell:Processing batches\n",
      "Processing batches: 100%|██████████| 136/136 [00:16<00:00,  8.14it/s]\n",
      "INFO:pdex._single_cell:Flattening results\n",
      "INFO:pdex._single_cell:Closing shared memory pool\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 2302.41 MiB, increment: 1187.94 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit -c parallel_differential_expression(adata, groupby_key=\"target_gene\", reference=\"non-targeting\", num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e837cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2480c6ffd5a147bca71f5be7cc2c9a52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 10572.84 MiB, increment: 1235.31 MiB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcf3adf027224002a029a798d4eeea35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/283 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 11838.17 MiB, increment: 3018.27 MiB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88c6ffb6180843eab43ed5c984f93be2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 11644.97 MiB, increment: 222.38 MiB\n"
     ]
    }
   ],
   "source": [
    "%load_ext memory_profiler\n",
    "%memit asymptotic_wilcoxon(adata, group_keys=\"target_gene\", reference_group=\"non-targeting\", is_log1p=False, n_threads=8, batch_size=256)\n",
    "%memit asymptotic_wilcoxon(adata, group_keys=\"target_gene\", reference_group=\"non-targeting\", is_log1p=False, n_threads=8, batch_size=64)\n",
    "\n",
    "%memit asymptotic_wilcoxon(adata, group_keys=\"target_gene\", reference_group=\"non-targeting\", is_log1p=False, n_threads=4, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7b5d199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b75361e19c1143e4ac21cbd3ecb7680e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 11810.62 MiB, increment: 5840.67 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit asymptotic_wilcoxon(adata, group_keys=\"target_gene\", reference_group=\"non-targeting\", is_log1p=False, n_threads=8, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b745ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata as ad\n",
    "\n",
    "h1 = ad.read_h5ad('/Users/remydubois/Documents/repos/vcc/data/competition_support_set/competition_train.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f581818f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4., 5., 6., ..., 0., 8., 1.],\n",
       "       [1., 4., 2., ..., 0., 2., 0.],\n",
       "       [3., 4., 1., ..., 0., 6., 0.],\n",
       "       ...,\n",
       "       [3., 2., 5., ..., 0., 7., 0.],\n",
       "       [1., 3., 6., ..., 0., 3., 0.],\n",
       "       [3., 8., 1., ..., 0., 3., 0.]], shape=(10000, 100), dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(h1.obs.target_gene.value_counts() // 500 * 500)\n",
    "\n",
    "rng = np.random.RandomState(0)\n",
    "\n",
    "# Random gene-specific mean expression levels\n",
    "gene_means = rng.uniform(0.1, 5, size=100)\n",
    "\n",
    "# Sample Poisson counts\n",
    "dense_counts = rng.poisson(gene_means, size=(10_000, 100)).astype(np.float32)\n",
    "dense_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "507caeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate test file\n",
    "# Group counts\n",
    "group_counts = h1.obs.target_gene.value_counts()\n",
    "group_counts.index = [\"control\"] + [f\"pert_{i}\" for i in range(1, len(group_counts))]\n",
    "group_counts.to_csv('../tests/data/group_counts.csv')\n",
    "\n",
    "# Compute sparsity\n",
    "sparsity = h1.X.data.size / np.prod(h1.X.shape)\n",
    "\n",
    "# Compute gene means\n",
    "mus = np.asarray(h1.X.mean(0)).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c759e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.4487075e-04, 7.2207469e-01, 1.6719058e-01, ..., 6.2261920e-02,\n",
       "       9.4395095e-01, 6.7493135e-01], shape=(18080,), dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_genes = mus.size\n",
    "n_cells = 2_000\n",
    "data_placeholder = np.empty(int(n_genes * n_genes * sparsity), dtype=np.float32)\n",
    "indices_placeholder = np.empty(int(n_genes * n_genes * sparsity), dtype=np.int32)\n",
    "for j in range(n_genes):\n",
    "    gene_data = rng.poisson(mus[j], size=n_cells).astype(np.float32)\n",
    "    non_zero_indices = np.nonzero(gene_data)[0]\n",
    "    col_start = int(j * n_genes * sparsity)\n",
    "    col_end = int((j + 1) * n_genes * sparsity)\n",
    "    data_placeholder[col_start:col_start + non_zero_indices.size] = gene_data[non_zero_indices]\n",
    "    indices_placeholder[col_start:col_start + non_zero_indices.size] = non_zero_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "69140fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 1, 1],\n",
       "       [0, 1, 0, ..., 0, 2, 0],\n",
       "       [0, 0, 0, ..., 0, 3, 2],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 1, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 2, 0, ..., 1, 2, 0]], shape=(100000, 18080))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng.poisson(mus, size=(100_000, mus.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fc044d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.4 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n",
      "6.96 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.random.normal(size=(150 * 1500 + 40_000))\n",
    "%timeit -n 1 -r 1 np.sort(x)\n",
    "%timeit -n 1 -r 1 [np.sort(x[i:i+1500]) for i in range(0, x.size, 1500)], np.sort(x[-40_000:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9be87b",
   "metadata": {},
   "source": [
    "# Warn log1p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "289f9163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float32'\n",
       "\twith 1932554688 stored elements and shape (221273, 18080)>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import anndata as ad\n",
    "import numpy as np\n",
    "from illico.utils.type import scipy_to_nb\n",
    "from numba import njit\n",
    "import scanpy as sc\n",
    "\n",
    "# h1 = ad.read_h5ad('../vcc_h1_904_genes.h5ad').layers[\"csr\"]\n",
    "h1 = ad.read_h5ad('/Users/remydubois/Documents/repos/vcc/data/competition_support_set/competition_train.h5').X\n",
    "h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b874cbe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(7.768956)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1.data.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00965cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.59 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6.7405195236206055"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@njit(nogil=True, cache=False)\n",
    "def sampled_max(data: np.ndarray, sample_size: int = 200_000) -> float:\n",
    "    max_val = -np.inf\n",
    "    n = data.size\n",
    "    step = max(1, n // sample_size)\n",
    "    for i in range(0, n, step):\n",
    "        if data[i] > max_val:\n",
    "            max_val = data[i]\n",
    "    return max_val\n",
    "\n",
    "sampled_max(h1.data[:1])\n",
    "%timeit -n 1 -r 1 sampled_max(h1.data)\n",
    "sampled_max(h1.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a65ee813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2e3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365fe9ed",
   "metadata": {},
   "source": [
    "# Datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e637642",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'h1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01manndata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mad\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# h1 = ad.read_h5ad('/Users/remydubois/Documents/repos/vcc/data/competition_support_set/competition_train.h5').X.tocsc()\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mh1\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'h1' is not defined"
     ]
    }
   ],
   "source": [
    "import anndata as ad\n",
    "\n",
    "# h1 = ad.read_h5ad('/Users/remydubois/Documents/repos/vcc/data/competition_support_set/competition_train.h5').X.tocsc()\n",
    "h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33700bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from scipy import sparse\n",
    "import anndata as ad\n",
    "# k562 = ad.read_h5ad('/Users/remydubois/Documents/repos/vcc/data/competition_support_set/k562_gwps.h5')\n",
    "k562 = ad.read_h5ad('/Users/remydubois/Documents/repos/vcc/data/competition_support_set/k562_gwps.h5')\n",
    "# org_X = k562.X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59118e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "k562.X = sparse.csc_matrix(k562.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0885d9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/remydubois/Documents/perso/repos/illico/illico/utils/math.py:150: UserWarning: User indicated is_log1p=False, but estimated data max value is 6.67, Which seems inconsistent. Make sure data is indeed raw counts.\n",
      "  warnings.warn(\n",
      "\u001b[32m2025-11-25 17:48:50.827\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36millico.asymptotic_wilcoxon\u001b[0m:\u001b[36masymptotic_wilcoxon\u001b[0m:\u001b[36m64\u001b[0m - \u001b[1mUsing batch size of 256 for 8 threads and 18080 genes.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37bcbbc012ab4be4823f20060b36cc93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3326720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from illico import asymptotic_wilcoxon\n",
    "import numpy as np\n",
    "\n",
    "asymptotic_wilcoxon(k562, is_log1p=False, group_keys=\"gene\", reference_group=\"non-targeting\", n_threads=8, batch_size=256);\n",
    "# np.testing.assert_allclose(k562.X[:1024], org_X[:1024])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef29f53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/remydubois/Documents/perso/repos/illico/illico/utils/math.py:150: UserWarning: User indicated is_log1p=False, but estimated data max value is 6.81, Which seems inconsistent. Make sure data is indeed raw counts.\n",
      "  warnings.warn(\n",
      "\u001b[32m2025-11-25 17:53:31.824\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36millico.asymptotic_wilcoxon\u001b[0m:\u001b[36masymptotic_wilcoxon\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mUsing batch size of 256 for 8 threads and 18080 genes.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "216d51b661a747c282f0387fb87c6185",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3326720 [00:00<?, ?test/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01millico\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m asymptotic_wilcoxon\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# k562.X = sparse.csc_matrix(k562.X)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43masymptotic_wilcoxon\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk562\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_log1p\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgene\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreference_group\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnon-targeting\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m256\u001b[39;49m\u001b[43m)\u001b[49m;\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/perso/repos/illico/illico/asymptotic_wilcoxon.py:35\u001b[39m, in \u001b[36masymptotic_wilcoxon\u001b[39m\u001b[34m(adata, is_log1p, group_keys, reference_group, n_threads, batch_size, alternative, use_continuity, layer)\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Perform asymptotic Wilcoxon-Mann-Whitney tests (one-versus-rest or one-versus-reference) on an AnnData object.\u001b[39;00m\n\u001b[32m     30\u001b[39m \n\u001b[32m     31\u001b[39m \u001b[33;03mIf `reference_group` is None, one-versus-rest tests are performed, otherwise one-versus-reference tests are performed.\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# TODO: add a sparsity warning inviting user to convert to sparse if possible\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m alternative != \u001b[33m\"\u001b[39m\u001b[33mtwo-sided\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     36\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCurrently only two-sided alternative is supported.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m use_continuity:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/perso/repos/illico/.venv/lib/python3.13/site-packages/joblib/parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/perso/repos/illico/.venv/lib/python3.13/site-packages/joblib/parallel.py:1820\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1817\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout_control_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1818\u001b[39m         timeout_control_job.get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout)\n\u001b[32m-> \u001b[39m\u001b[32m1820\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1821\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1823\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m timeout_control_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1824\u001b[39m     \u001b[38;5;66;03m# Case unordered, when `nb_jobs > 0`:\u001b[39;00m\n\u001b[32m   1825\u001b[39m     \u001b[38;5;66;03m# It means that a job is ready to be retrieved, so no timeout\u001b[39;00m\n\u001b[32m   1826\u001b[39m     \u001b[38;5;66;03m# will occur during this iteration.\u001b[39;00m\n\u001b[32m   1827\u001b[39m     \u001b[38;5;66;03m# Before proceeding to retrieval of the next ready job, reset\u001b[39;00m\n\u001b[32m   1828\u001b[39m     \u001b[38;5;66;03m# the timeout control state to prepare the next iteration.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from illico import asymptotic_wilcoxon\n",
    "# k562.X = sparse.csc_matrix(k562.X)\n",
    "asymptotic_wilcoxon(k562, is_log1p=False, group_keys=\"gene\", reference_group=\"non-targeting\", n_threads=8, batch_size=256);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d108ecdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from illico.utils.ranking import sort_along_axis\n",
    "from illico.ovo import csc_ovo_mwu_kernel_over_contiguous_col_chunk, dense_ovo_mwu_kernel_over_contiguous_col_chunk\n",
    "from illico.utils.groups import encode_and_count_groups\n",
    "from illico.utils.type import scipy_to_nb\n",
    "\n",
    "grpc = encode_and_count_groups(k562.obs['gene'].tolist(), ref_group='non-targeting')\n",
    "# x = k562[k562.obs['gene'] == 'non-targeting'].X[:, :1024]\n",
    "# sort_along_axis(x[:1], axis=0)\n",
    "# %timeit -n 1 -r 1 np.sort(x, axis=0)\n",
    "# %timeit -n 1 -r 1 sort_along_axis(x, axis=0)\n",
    "# %timeit -n 1 -r 1 sparse.csc_matrix(x)\n",
    "\n",
    "# chunk = k562.X[:, :1024].copy()\n",
    "# chunk = np.ones((k562.X.shape[0], 1024), dtype=np.float32)\n",
    "# for sparsity_rate in np.arange(0., 1., 0.1):\n",
    "#     if sparsity_rate > 0.0:\n",
    "#         step = int(1 / sparsity_rate)\n",
    "#         chunk[::step] = 0\n",
    "#     print('----- sparsity rate:', sparsity_rate, \"avg expression value:\", chunk.mean())\n",
    "#     csc_chunk = scipy_to_nb(sparse.csc_matrix(chunk))\n",
    "#     csc_ovo_mwu_kernel_over_contiguous_col_chunk(csc_chunk, 0, 1, grpc, is_log1p=False);\n",
    "#     %timeit -n 1 -r 1 csc_ovo_mwu_kernel_over_contiguous_col_chunk(scipy_to_nb(sparse.csc_matrix(chunk)), 0, 1024, grpc, is_log1p=False);\n",
    "#     chunk[:] = 1\n",
    "# dense_ovo_mwu_kernel_over_contiguous_col_chunk(chunk, 0, 1, grpc, is_log1p=False)\n",
    "# %timeit -n 1 -r 1 dense_ovo_mwu_kernel_over_contiguous_col_chunk(chunk, 0, 1024, grpc, is_log1p=False);\n",
    "# %timeit -n 1 -r 1 csc_ovo_mwu_kernel_over_contiguous_col_chunk(scipy_to_nb(sparse.csc_matrix(chunk)), 0, 1024, grpc, is_log1p=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "31c0ad02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.1 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n",
      "34.7 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "from illico.ovo.dense_ovo import dense_ovo_mwu_kernel_over_contiguous_col_chunk, dense_ovo_mwu_kernel\n",
    "from illico.ovo.sparse_ovo import single_group_sparse_ovo_mwu_kernel\n",
    "ref_indices = grpc.indices[grpc.indptr[grpc.encoded_ref_group]:grpc.indptr[grpc.encoded_ref_group + 1]]\n",
    "pert_indices = grpc.indices[grpc.indptr[0]:grpc.indptr[1]]\n",
    "# X_ref = np.sort(k562.X[ref_indices, :1024], axis=0)\n",
    "# X_pert = np.sort(k562.X[pert_indices, :1024], axis=0)\n",
    "X_ref = np.ones((len(ref_indices), 1024), dtype=np.float32, order=\"F\")\n",
    "X_pert = np.ones((len(pert_indices), 1024), dtype=np.float32, order=\"F\")\n",
    "%timeit -n 1 -r 1 dense_ovo_mwu_kernel(sorted_ref_data=X_ref, sorted_tgt_data=X_pert)\n",
    "csc_X_ref = scipy_to_nb(sparse.csc_matrix(X_ref))\n",
    "csc_X_pert = scipy_to_nb(sparse.csc_matrix(X_pert))\n",
    "%timeit -n 1 -r 1 single_group_sparse_ovo_mwu_kernel(sorted_ref_data=csc_X_ref, sorted_tgt_data=csc_X_pert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2ef55b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289 μs ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n",
      "150 μs ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n",
      "23.5 μs ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n",
      "28.2 μs ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "from illico.utils.ranking import rank_sum_and_ties_from_sorted\n",
    "\n",
    "f_X_ref = np.asfortranarray(X_ref)\n",
    "f_X_pert = np.asfortranarray(X_pert)\n",
    "x, y = f_X_ref[:, 0], f_X_pert[:, 0]\n",
    "%timeit -n 1 -r 1 rank_sum_and_ties_from_sorted(X_ref[:, 0], X_pert[:, 0])\n",
    "%timeit -n 1 -r 1 rank_sum_and_ties_from_sorted(f_X_ref[:, 0], f_X_pert[:, 0])\n",
    "%timeit -n 1 -r 1 rank_sum_and_ties_from_sorted(x, y)\n",
    "%timeit -n 1 -r 1 rank_sum_and_ties_from_sorted(csc_X_ref.data[0:75328], csc_X_pert.data[0:152])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6873b1b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  C_CONTIGUOUS : True\n",
       "  F_CONTIGUOUS : True\n",
       "  OWNDATA : False\n",
       "  WRITEABLE : True\n",
       "  ALIGNED : True\n",
       "  WRITEBACKIFCOPY : False"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_X_ref[:, 0].flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6982d02d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  C_CONTIGUOUS : True\n",
       "  F_CONTIGUOUS : True\n",
       "  OWNDATA : False\n",
       "  WRITEABLE : True\n",
       "  ALIGNED : True\n",
       "  WRITEBACKIFCOPY : False"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csc_X_ref.data[0:75328].flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d547ce6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 1., 1., ..., 1., 1., 1.], shape=(1024,)),\n",
       " array([5724928., 5724928., 5724928., ..., 5724928., 5724928., 5724928.],\n",
       "       shape=(1024,)))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %lprun -u 1e-3 -f single_group_sparse_ovo_mwu_kernel.__wrapped__ single_group_sparse_ovo_mwu_kernel.__wrapped__(sorted_ref_data=csc_X_ref, sorted_tgt_data=csc_X_pert)\n",
    "single_group_sparse_ovo_mwu_kernel(sorted_ref_data=csc_X_ref, sorted_tgt_data=csc_X_pert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7f633a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/remydubois/Documents/perso/repos/illico/illico/utils/math.py:150: UserWarning: User indicated is_log1p=False, but estimated data max value is 6.67, Which seems inconsistent. Make sure data is indeed raw counts.\n",
      "  warnings.warn(\n",
      "\u001b[32m2025-11-25 15:15:28.681\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36millico.asymptotic_wilcoxon\u001b[0m:\u001b[36masymptotic_wilcoxon\u001b[0m:\u001b[36m64\u001b[0m - \u001b[1mUsing batch size of 1024 for 1 threads and 18080 genes.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fdace61133f4d5995839e40be13bb86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from illico import asymptotic_wilcoxon\n",
    "asymptotic_wilcoxon(k562, is_log1p=False, group_keys=\"gene\", reference_group=\"non-targeting\", n_threads=1, batch_size=1024)\n",
    "# k562.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4cf94a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pdex._single_cell:Auto-Detected log1p for dataset.\n",
      "INFO:pdex._single_cell:Log1p status: True\n",
      "INFO:pdex._single_cell:Precomputing masks for each target gene\n",
      "Identifying target masks: 100%|██████████| 184/184 [00:00<00:00, 23434.00it/s]\n",
      "INFO:pdex._single_cell:Precomputing variable indices for each feature\n",
      "Identifying variable indices: 100%|██████████| 18080/18080 [00:00<00:00, 7538822.58it/s]\n",
      "INFO:pdex._single_cell:Creating shared memory memory matrix for parallel computing\n",
      "INFO:pdex._single_cell:Creating generator of all combinations: N=3326720\n",
      "INFO:pdex._single_cell:Creating generator of all batches: N=33268\n",
      "INFO:pdex._single_cell:Initializing parallel processing pool\n",
      "INFO:pdex._single_cell:Processing batches\n",
      "Processing batches:   1%|▏         | 485/33268 [00:35<50:23, 10.84it/s]  Process SpawnPoolWorker-6:\n",
      "Process SpawnPoolWorker-5:\n",
      "Processing batches:   1%|▏         | 486/33268 [00:35<40:25, 13.51it/s]Process SpawnPoolWorker-8:\n",
      "\n",
      "Process SpawnPoolWorker-2:\n",
      "Process SpawnPoolWorker-1:\n",
      "Process SpawnPoolWorker-4:\n",
      "Process SpawnPoolWorker-7:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/remydubois/.pyenv/versions/3.13.7/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/Users/remydubois/.pyenv/versions/3.13.7/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/remydubois/.pyenv/versions/3.13.7/lib/python3.13/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "                    ~~~~^^^^^^^^^^^^^^^\n",
      "  File \"/Users/remydubois/Documents/perso/repos/illico/.venv/lib/python3.13/site-packages/pdex/_single_cell.py\", line 158, in _process_target_batch_shm\n",
      "    μ_tgt = _sample_mean(x_tgt, is_log1p=is_log1p, exp_post_agg=exp_post_agg)\n",
      "            ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/remydubois/Documents/perso/repos/illico/.venv/lib/python3.13/site-packages/pdex/_single_cell.py\", line 234, in _sample_mean\n",
      "    def _sample_mean(\n",
      "    \n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/remydubois/.pyenv/versions/3.13.7/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/Users/remydubois/.pyenv/versions/3.13.7/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/remydubois/.pyenv/versions/3.13.7/lib/python3.13/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "                    ~~~~^^^^^^^^^^^^^^^\n",
      "  File \"/Users/remydubois/Documents/perso/repos/illico/.venv/lib/python3.13/site-packages/pdex/_single_cell.py\", line 158, in _process_target_batch_shm\n",
      "    μ_tgt = _sample_mean(x_tgt, is_log1p=is_log1p, exp_post_agg=exp_post_agg)\n",
      "            ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/remydubois/Documents/perso/repos/illico/.venv/lib/python3.13/site-packages/pdex/_single_cell.py\", line 234, in _sample_mean\n",
      "    def _sample_mean(\n",
      "    \n",
      "KeyboardInterrupt\n",
      "  File \"/Users/remydubois/.pyenv/versions/3.13.7/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/Users/remydubois/.pyenv/versions/3.13.7/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/remydubois/.pyenv/versions/3.13.7/lib/python3.13/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "                    ~~~~^^^^^^^^^^^^^^^\n",
      "  File \"/Users/remydubois/Documents/perso/repos/illico/.venv/lib/python3.13/site-packages/pdex/_single_cell.py\", line 158, in _process_target_batch_shm\n",
      "    μ_tgt = _sample_mean(x_tgt, is_log1p=is_log1p, exp_post_agg=exp_post_agg)\n",
      "            ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/remydubois/Documents/perso/repos/illico/.venv/lib/python3.13/site-packages/pdex/_single_cell.py\", line 234, in _sample_mean\n",
      "    def _sample_mean(\n",
      "    \n",
      "  File \"/Users/remydubois/.pyenv/versions/3.13.7/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/Users/remydubois/.pyenv/versions/3.13.7/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/remydubois/.pyenv/versions/3.13.7/lib/python3.13/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "                    ~~~~^^^^^^^^^^^^^^^\n",
      "  File \"/Users/remydubois/Documents/perso/repos/illico/.venv/lib/python3.13/site-packages/pdex/_single_cell.py\", line 158, in _process_target_batch_shm\n",
      "    μ_tgt = _sample_mean(x_tgt, is_log1p=is_log1p, exp_post_agg=exp_post_agg)\n",
      "            ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/remydubois/Documents/perso/repos/illico/.venv/lib/python3.13/site-packages/pdex/_single_cell.py\", line 234, in _sample_mean\n",
      "    def _sample_mean(\n",
      "    \n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/remydubois/.pyenv/versions/3.13.7/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/Users/remydubois/.pyenv/versions/3.13.7/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/remydubois/.pyenv/versions/3.13.7/lib/python3.13/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "                    ~~~~^^^^^^^^^^^^^^^\n",
      "  File \"/Users/remydubois/Documents/perso/repos/illico/.venv/lib/python3.13/site-packages/pdex/_single_cell.py\", line 170, in _process_target_batch_shm\n",
      "    de_result = mannwhitneyu(\n",
      "        x_tgt, x_ref, use_continuity=True, **kwargs\n",
      "    )\n",
      "  File \"/Users/remydubois/Documents/perso/repos/illico/.venv/lib/python3.13/site-packages/scipy/stats/_axis_nan_policy.py\", line 470, in axis_nan_policy_wrapper\n",
      "    kwds.update(d_args)\n",
      "    ~~~~~~~~~~~^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/remydubois/.pyenv/versions/3.13.7/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/Users/remydubois/.pyenv/versions/3.13.7/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/remydubois/.pyenv/versions/3.13.7/lib/python3.13/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "                    ~~~~^^^^^^^^^^^^^^^\n",
      "  File \"/Users/remydubois/Documents/perso/repos/illico/.venv/lib/python3.13/site-packages/pdex/_single_cell.py\", line 170, in _process_target_batch_shm\n",
      "    de_result = mannwhitneyu(\n",
      "        x_tgt, x_ref, use_continuity=True, **kwargs\n",
      "    )\n",
      "  File \"/Users/remydubois/Documents/perso/repos/illico/.venv/lib/python3.13/site-packages/scipy/stats/_axis_nan_policy.py\", line 579, in axis_nan_policy_wrapper\n",
      "    res = hypotest_fun_out(*samples, **kwds)\n",
      "  File \"/Users/remydubois/Documents/perso/repos/illico/.venv/lib/python3.13/site-packages/scipy/stats/_mannwhitneyu.py\", line 447, in mannwhitneyu\n",
      "    x, y, xy = _broadcast_concatenate(x, y, axis)\n",
      "               ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
      "  File \"/Users/remydubois/Documents/perso/repos/illico/.venv/lib/python3.13/site-packages/scipy/stats/_mannwhitneyu.py\", line 17, in _broadcast_concatenate\n",
      "    z = np.concatenate((x, y), axis=-1)\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/remydubois/.pyenv/versions/3.13.7/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/Users/remydubois/.pyenv/versions/3.13.7/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/remydubois/.pyenv/versions/3.13.7/lib/python3.13/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "                    ~~~~^^^^^^^^^^^^^^^\n",
      "  File \"/Users/remydubois/Documents/perso/repos/illico/.venv/lib/python3.13/site-packages/pdex/_single_cell.py\", line 170, in _process_target_batch_shm\n",
      "    de_result = mannwhitneyu(\n",
      "        x_tgt, x_ref, use_continuity=True, **kwargs\n",
      "    )\n",
      "  File \"/Users/remydubois/Documents/perso/repos/illico/.venv/lib/python3.13/site-packages/scipy/stats/_axis_nan_policy.py\", line 458, in axis_nan_policy_wrapper\n",
      "    maxarg = (np.inf if inspect.getfullargspec(hypotest_fun_in).varargs\n",
      "                        ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/remydubois/.pyenv/versions/3.13.7/lib/python3.13/inspect.py\", line 1364, in getfullargspec\n",
      "    sig = _signature_from_callable(func,\n",
      "                                   follow_wrapper_chains=False,\n",
      "                                   skip_bound_arg=False,\n",
      "                                   sigcls=Signature,\n",
      "                                   eval_str=False)\n",
      "  File \"/Users/remydubois/.pyenv/versions/3.13.7/lib/python3.13/inspect.py\", line 2587, in _signature_from_callable\n",
      "    return _signature_from_function(sigcls, obj,\n",
      "                                    skip_bound_arg=skip_bound_arg,\n",
      "                                    globals=globals, locals=locals, eval_str=eval_str)\n",
      "  File \"/Users/remydubois/.pyenv/versions/3.13.7/lib/python3.13/inspect.py\", line 2434, in _signature_from_function\n",
      "    for offset, name in enumerate(positional[non_default_count:]):\n",
      "                        ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "Process SpawnPoolWorker-3:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/remydubois/.pyenv/versions/3.13.7/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/Users/remydubois/.pyenv/versions/3.13.7/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/remydubois/.pyenv/versions/3.13.7/lib/python3.13/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "                    ~~~~^^^^^^^^^^^^^^^\n",
      "  File \"/Users/remydubois/Documents/perso/repos/illico/.venv/lib/python3.13/site-packages/pdex/_single_cell.py\", line 204, in _process_target_batch_shm\n",
      "    existing_shm.close()\n",
      "    ~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/Users/remydubois/.pyenv/versions/3.13.7/lib/python3.13/multiprocessing/shared_memory.py\", line 232, in close\n",
      "    self._mmap.close()\n",
      "    ~~~~~~~~~~~~~~~~^^\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.13.7/lib/python3.13/multiprocessing/pool.py:856\u001b[39m, in \u001b[36mIMapIterator.next\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    855\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m856\u001b[39m     item = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_items\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpopleft\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    857\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n",
      "\u001b[31mIndexError\u001b[39m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpdex\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m parallel_differential_expression\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpdex\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_single_cell\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m parallel_differential_expression_vec_wrapper\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mparallel_differential_expression\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk562\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroupby_key\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgene\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreference\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnon-targeting\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/perso/repos/illico/.venv/lib/python3.13/site-packages/pdex/_single_cell.py:417\u001b[39m, in \u001b[36mparallel_differential_expression\u001b[39m\u001b[34m(adata, groups, reference, groupby_key, num_workers, batch_size, metric, tie_correct, is_log1p, exp_post_agg, clip_value, as_polars, **kwargs)\u001b[39m\n\u001b[32m    415\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m mp.Pool(num_workers) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[32m    416\u001b[39m     logger.info(\u001b[33m\"\u001b[39m\u001b[33mProcessing batches\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m417\u001b[39m     batch_results = \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    418\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    419\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatches\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    420\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_batches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mProcessing batches\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    422\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    423\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[38;5;66;03m# Flatten results\u001b[39;00m\n\u001b[32m    426\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33mFlattening results\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/perso/repos/illico/.venv/lib/python3.13/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.13.7/lib/python3.13/multiprocessing/pool.py:861\u001b[39m, in \u001b[36mIMapIterator.next\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    859\u001b[39m     \u001b[38;5;28mself\u001b[39m._pool = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    860\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m861\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cond\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    862\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    863\u001b[39m     item = \u001b[38;5;28mself\u001b[39m._items.popleft()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.13.7/lib/python3.13/threading.py:359\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    357\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[32m    358\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m         \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    360\u001b[39m         gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    361\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "from pdex import parallel_differential_expression\n",
    "from pdex._single_cell import parallel_differential_expression_vec_wrapper\n",
    "\n",
    "parallel_differential_expression(k562, groupby_key=\"gene\", reference=\"non-targeting\", num_workers=8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "illico-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
